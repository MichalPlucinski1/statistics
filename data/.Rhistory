sin(2*PI)
sin(2*PI)
sin(2*pi)
sin(2*pi)
log(100)
chem = read.csv("Reg_chemikalia.csv", sep=";")
setwd("E:/polibuda/s4/statystyka/data")
#a)punktowy przedstawiający zależność wielkości produkcji od ilości zużytego
chem = read.csv("Reg_chemikalia.csv", sep=";")
x = chem$surowiec
y = chem$produkt
#a)
plot(y~x) # y~x = y zależy od x
n = length(x)
cov(x, y) #138.4889
1/(n-1)*(sum(x*y)-length(x)*(mean(x)*mean(y))) #138.4889
cov(x, y) #138.4889
1/(n-1)*(sum(x*y)-length(x)*(mean(x)*mean(y))) #138.4889
cor(x, y) #0.895
cov(x, y)/(sd(x)*sd(y)) #0.895
sd(x)
x
curve(b0hat + b1hat*x, 0, 30, add=T)
###################################################################
#  1 regresja   wykres punktowy przedstawiający zależność wielkości produkcji od ilości zużytego
###################################################################
#wyznaczyć relację miedzy końcową
#wielkością produkcji środków chemicznych Y (w kg)
#w zależności od ilości zużytego surowca X (w litrach)
#a)punktowy przedstawiający zależność wielkości produkcji od ilości zużytego
chem = read.csv("Reg_chemikalia.csv", sep=";")
x = chem$surowiec
y = chem$produkt
#a)
plot(y~x) # y~x = y zależy od x
#b
#Wyznacz i zinterpretuj kowariancję próbkową między ilością zużytego surowca a wielkością produkcji.
n = length(x)
cov(x, y) #138.4889
1/(n-1)*(sum(x*y)-length(x)*(mean(x)*mean(y))) #138.4889
# Kowariancja nie jest zerowa, a więc istnieje pewna
# liniowa zależność między ilością produktu a wykorzystaną ilością surowcem
# c
#Wyznacz i zinterpretuj współczynnik korelacji.
cor(x, y) #0.895
cov(x, y)/(sd(x)*sd(y)) #0.895
# Istnieje bardzo silna dodatnia zależność liniowa między
# ilością produktu, a wykorzystaną ilośćią surowca
#d
#Wyznacz ocenę prostej regresji między wielkością produkcji a ilością zużytego surowca.
#LSE
b1hat = cov(x, y)/var(x) #3.619
b0hat = mean(y) - b1*mean(x) #22.404
cor(x, y) #0.895
cov(x, y)/(sd(x)*sd(y)) #0.895
# I
cor(x, y) #0.895
cov(x, y)/(sd(x)*sd(y)) #0.895
#LSE
b1hat = cov(x, y)/var(x) #3.619
b0hat = mean(y) - b1*mean(x) #22.404
#LSE
b1hat = cov(x, y)/var(x) #3.619
b0hat = mean(y) - b1*mean(x) #22.404
b1hat = cov(x, y)/var(x) #3.619
b0hat
b1hat = cov(x, y)/var(x) #3.619
b0hat = mean(y) - b1*mean(x) #22.404
a !
#1.
chem = read.csv("Reg_chemikalia.csv", sep=";")
x = chem$surowiec
y = chem$produkt
#a)
plot(y~x) # y~x = y zależy od x
#b)
n = length(x)
cov(x, y) #138.4889
1/(n-1)*(sum(x*y)-length(x)*(mean(x)*mean(y))) #138.4889
# Kowariancja nie jest zerowa, a więc istnieje pewna
# liniowa zależność między ilością produktu a wykorzystaną ilością surowcem
#c)
cor(x, y) #0.895
cov(x, y)/(sd(x)*sd(y)) #0.895
# Istnieje bardzo silna dodatnia zależność liniowa między
# ilością produktu, a wykorzystaną ilośćią surowca
#d)
#LSE
b1hat = cov(x, y)/var(x) #3.619
b0hat = mean(y) - b1*mean(x) #22.404
#LSE
b1hat = cov(x, y)/var(x) #3.619
b0hat = mean(y) - b1hat*mean(x) #22.404
b0hat
b1hat
prosta = lm(y~x)
prosta$coefficients #Intercept = b0hat, x = b1hat
b0hat = prosta$coefficients[1]
b1hat = prosta$coefficients[2]
#e)
#Dodaj do wykresu punktowego prostą regresji.
curve(b0hat + b1hat*x, 0, 30, add=T)
abline(prosta)
obs=c(122, 85, 76, 17)
n = sum(obs)
teor=c(0.38*n, 0.32*n, 0.23*n, 0.07*n)
teor
alpha = 0.1
chisq.test(obs, p = teor/n) #p.val = 0.3485 df = 3 (ilość kategorii - 1)
teor=c(0.74 * n, 0.16 * n, 0.1 * n)
alpha = 0.1
chisq.test(obs, p = teor/n) #p.val = 0.3485 df = 3 (ilość kategorii - 1)
obs=c(68, 27, 5)
n = sum(obs)
teor=c(0.74 * n, 0.16 * n, 0.1 * n)
alpha = 0.1
chisq.test(obs, p = teor/n) #p.val = 0.3485 df = 3 (ilość kategorii - 1)
chisq.test(obs, p = teor/n) #p.val = 0.3485 df = 3 (ilość kategorii - 1)
file=read.csv("normalnosc_ozon.csv",sep=";",dec=",")
file
ozon=file$ozon
ozon
br=c(0,2,4,6,8,10,12)
k=length(br)-1
series=cut(ozon,br)
series
y=table(series)
y
source("E:/polibuda/s4/statystyka/l1/chi2.R", echo=TRUE)
m=mean(ozon)
s=sd(ozon)
n=length(ozon)
hist(ozon,br,freq=F)
curve(dnorm(x,m,s),xlim=c(br[1],br[k+1]),col=3, add=TRUE)
observedf=c();
for (i in 1:dim(y)){
observedf=c(observedf,y[[i]])
}
observedf
observedf
normprobabilities=c();
for (i in 1:length(br)-1) {
normprobabilities=c(normprobabilities,pnorm(br[i+1],m,s)-pnorm(br[i],m,s))
}
normprobabilities[1]=pnorm(br[2],m,s)
normprobabilities[length(br)-1]=1-pnorm(br[length(br)-1],m,s)
normalfreq=normprobabilities*n
normalfreq
normalfreq[k-1]=normalfreq[k-1]+normalfreq[k]
normalfreq=normalfreq[-c(k)]
normalfreq[k-1]=normalfreq[k-1]+normalfreq[k]
normalfreq=normalfreq[-c(k)]
normalfreq
observedf[k-1]=observedf[k-1]+observedf[k]
observedf=observedf[-c(k)]
observedf
normalfreq
observedf
k=k-1
expectedp=normalfreq/sum(normalfreq)
expectedp
chisq.test(observedf,p=expectedp)
points = read.csv("normalnosc_punkty.csv", sep = ";")
ozon = read.csv("normalnosc_ozon.csv", sep=";")
#1.
obs=c(122, 85, 76, 17)
n = sum(obs)
teor=c(0.38*n, 0.32*n, 0.23*n, 0.07*n)
alpha = 0.1
# Hipoteza
# Każda częstość występowania jest równa tej teoretycznej
# H0: rozkład częstości pracujących emerytów
#     ze względu na typ pracy jest zgodny z oczekiwaniem
# H1: co najmniej jedna ta częstość jest inna
# Trzeba uważać na precyzje floating point
chisq.test(obs, p = teor/n) #p.val = 0.3485 df = 3 (ilość kategorii - 1)
# alpha = 0.1 < p.value => nie odrzucamy H0
#Interpretacja
# Na poziomie istotności 10% dane nie potwierdzając, że społeczność
# emerycka różni się od oczekiwanej prognozy
#2.
obs=c(68, 27, 5)
n=sum(obs)
teor=c(0.74*n, 0.16*n, 0.10*n)
prop=c(0.74, 0.16, 0.10)
chisq.test(obs, p=prop)# p.val = 0.005121
#alpha = 0.1 > p.val -> odrzucamy H0
#Interpretacja
# Na poziomie istotności 10% dane potwierdzają, że odsetki poszczególnych
# zgonów rożni się od przedstawionych w artykule
#4.
# Z pliku
####################################################
file=read.csv("normalnosc_ozon.csv",sep=";",dec=",")
ozon=file$ozon
br=c(0,2,4,6,8,10,12)
k=length(br)-1
series=cut(ozon,br)
y=table(series)
m=mean(ozon)
s=sd(ozon)
n=length(ozon)
hist(ozon,br,freq=F)
curve(dnorm(x,m,s),xlim=c(br[1],br[k+1]),col=3, add=TRUE)
observedf=c();
for (i in 1:dim(y)){
observedf=c(observedf,y[[i]])
}
observedf
normprobabilities=c();
for (i in 1:length(br)-1) {
normprobabilities=c(normprobabilities,pnorm(br[i+1],m,s)-pnorm(br[i],m,s))
}
normprobabilities[1]=pnorm(br[2],m,s)
normprobabilities[length(br)-1]=1-pnorm(br[length(br)-1],m,s)
normalfreq=normprobabilities*n
normalfreq
#Zauważmy, że w dwóch ostatnich klasach mamy mniej niż 5 obserwacji. Dlatego musimy połączyć te klasy.
normalfreq[k-1]=normalfreq[k-1]+normalfreq[k]
normalfreq=normalfreq[-c(k)]
observedf[k-1]=observedf[k-1]+observedf[k]
observedf=observedf[-c(k)]
normalfreq
observedf
k=k-1
expectedp=normalfreq/sum(normalfreq)
expectedp
chisq.test(observedf,p=expectedp)
###################################################################
#     1  chi2 1
###################################################################
points = read.csv("normalnosc_punkty.csv", sep = ";")
ozon = read.csv("normalnosc_ozon.csv", sep=";")
# 1 test
#38% było zatrudnionych w innej
#32% samozatrudnionych,
#23% było freelancerami lub konsultantami,
#a 7% założyło własne firmy
# 2 test
# 300 emerytowanych menedżerów
#122 pracowało dla innej firmy,
#85 prowadziło działalność na własny rachunek,
#76 pracowało jako freelancer
#lub doradzało, a 17 założyło własne firmy.
#Czy przy istotności 10% dane potwierdzają, że odsetki
#poszczególnych zatrudnionych w hrabstwie Allegheny różnią się od ich
#odpowiedników w skali całego kraju?
obs=c(122, 85, 76, 17)
n = sum(obs)
teor=c(0.38*n, 0.32*n, 0.23*n, 0.07*n)
alpha = 0.1
# Hipoteza
# Każda częstość występowania jest równa tej teoretycznej
# H0: rozkład częstości pracujących emerytów
#     ze względu na typ pracy jest zgodny z oczekiwaniem
# H1: co najmniej jedna ta częstość jest inna
# Trzeba uważać na precyzje floating point
chisq.test(obs, p = teor/n) #p.val = 0.3485 df = 3 (ilość kategorii - 1)
# alpha = 0.1 < p.value => nie odrzucamy H0
#Interpretacja
# Na poziomie istotności 10% dane nie potwierdzając, że społeczność
# emerycka różni się od oczekiwanej prognozy
###################################################################
#     2  chi2 2
###################################################################
#74% to wypadki, 16% to zabójstwa, a 10% to samobójstw
# 68 wypadków śmiertelnych,
#27 zabójstw i
#5 samobójstw.
#istotności 10% dane potwierdzają,
#że odsetki poszczególnych zgonów różnią się od przedstawionych w artykule?
obs=c(68, 27, 5)
n = sum(obs)
teor=c(0.74 * n, 0.16 * n, 0.1 * n)
alpha = 0.1
chisq.test(obs, p = teor/n) #p.val = 0.3485 df = 3 (ilość kategorii - 1)
# 0.005 < alpha -> odrzucamy h0
#Interpretacja
# Na poziomie istotności 10% dane potwierdzają, że odsetki poszczególnych
# zgonów rożni się od przedstawionych w artykule
###################################################################
#     4  chi2 4     pogrupowane w przedziały, czy stężenie ma rozkład normalny
###################################################################
# stezenie ozonu
# 78 kolejnych dni
# Z pliku
file=read.csv("normalnosc_ozon.csv",sep=";",dec=",")
ozon=file$ozon
br=c(0,2,4,6,8,10,12)
k=length(br)-1
series=cut(ozon,br)
y=table(series) # tabela grup, tworzenie grup
m=mean(ozon)
s=sd(ozon)
n=length(ozon)
hist(ozon,br,freq=F)
curve(dnorm(x,m,s),xlim=c(br[1],br[k+1]),col=3, add=TRUE)
observedf=c();
for (i in 1:dim(y)){
observedf=c(observedf,y[[i]])
}
observedf
normprobabilities=c();
for (i in 1:length(br)-1) {
normprobabilities=c(normprobabilities,pnorm(br[i+1],m,s)-pnorm(br[i],m,s))
}
normprobabilities[1]=pnorm(br[2],m,s)
normprobabilities[length(br)-1]=1-pnorm(br[length(br)-1],m,s)
normalfreq=normprobabilities*n
normalfreq
#Zauważmy, że w dwóch ostatnich klasach mamy mniej niż 5 obserwacji.
#Dlatego musimy połączyć te klasy.
normalfreq[k-1]=normalfreq[k-1]+normalfreq[k]
normalfreq=normalfreq[-c(k)]
observedf[k-1]=observedf[k-1]+observedf[k]
observedf=observedf[-c(k)]
normalfreq
observedf
k=k-1
expectedp=normalfreq/sum(normalfreq)
expectedp
chisq.test(observedf,p=expectedp)
pearson.test(ozon, n.classes = 6, adjust=F) #p.val1 = 0.3708
install.packages("nortest")
# Pearson p.val tak naprawdę jest między p.val1, a p.val2
pearson.test(ozon, n.classes = 6, adjust=F) #p.val1 = 0.3708
library(nortest)
# Pearson p.val tak naprawdę jest między p.val1, a p.val2
pearson.test(ozon, n.classes = 6, adjust=F) #p.val1 = 0.3708
pearson.test(ozon, n.classes = 6, adjust=T) #p.val2 = 0.1457
# tak czy siak p.val > alpha = 0.05
# Nie odrzucamy H0
punkty = points$punkty
cvm.test(punkty) # p.val małe
cvm.test(punkty) # p.val małe
ad.test(punkty)  # p.val małe
shapiro.test(punkty) #p.val małe
br=seq(min(punkty), max(punkty), length=6)
hist(punkty, br, freq=F)
tak=c(10,7,4)
nie=c(90,93,96)
#H0: nie ma zależności miedzy proporcja
#    zgubionych bagazy, a linia lotnicza
TK = data.frame(tak, nie) # Tablica Kontyngencji
TK
chisq.test(TK) #p.val = 0.251
# alpha < p.val nie odrzucamy H0
za =c(96, 96, 90, 36)
przeciw = c(201, 189, 195, 234)
nw = c(3,15,15,30)
tk = data.frame(za, przeciw, nw)
tk
chisq.test(tk) # p.val = 0
